else
{
CumulativeSeperatedRunCost[run,1]=CumulativeSeperatedRunCost[run-1,1]+SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=CumulativeSeperatedRunCost[run-1,2]+SeperatedRunCost[run,2]
}
print(paste("Cost of action is",toString(RunCost[run])))
#Evolve System
sVec=NewSState(OldsVec,MoveToNode,BVec)
#print("Evolved S is ")
#print(sVec)
#Creating new vVec using scenario
vVec=OldvVec
vVec[MoveToNode]=min(SimulationScenario[MoveToNode,TrackingScenario[MoveToNode]],bVec[MoveToNode])
TrackingScenario[MoveToNode]=TrackingScenario[MoveToNode]+1
#vVec=NewMeanVState(OldvVec,sVec,MoveToNode,BVec,bVec,LambdaVec)
#print("Evolved v is")
#print(vVec)
AllInfo[[run,1]]=c(sVec,vVec)
AllInfo[[run,2]]=MoveToNode
AllInfo[[run,3]]=SeperatedRunCost[run,1]
AllInfo[[run,4]]=SeperatedRunCost[run,2]
print(paste("Moved to ",toString(MoveToNode),"Costing ",toString(RunCost[run])))
}
}
AverageCost=sum(RunCost)/NumberOfRunSteps
print(paste("Average cost is ",toString(AverageCost)))
return(list(Average=AverageCost,CostForStep=RunCost,SeperatedCostForStep=SeperatedRunCost,CumulativeSeperatedCostForStep=CumulativeSeperatedRunCost,FullInfoMatrix=AllInfo))
}
FullInfoMatrix=SimulationForEvolution(1000,3,MultiStepBenefitHeuristic,4,matrix(rep(1,16),nrow=4),PlainIndexForNode,rep(1,4),rep(1/4,4),rep(1,4),c(1.2,1.8,2.2,2.8))$FullInfoMatrix
FullInfoMatrix
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace)
View(StateSpace)
View(StateSpace)
View(States)
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace)
source("Heuristics.R")
library(stats)
library(ggplot2)
library(reshape2)
#This function returns a vector for the simulation to use
CreateSimulationScenario<-function(NoSteps,n,LambdaVec)
{
Scenario=matrix(0,nrow=n,ncol=NoSteps)
for(i in 1:n)
{
for(j in 1:NoSteps)
{
Scenario[i,j]=rpois(1,LambdaVec[i])
}
}
return(Scenario)
}
# SimulateVStateEvolution<-function(NodeToEvolve,NewsVec,vVec,xVec,LambdaVec,bVec)
# {
#   BVec=ceiling(xVec)
#   #NewvVec=(NewVState(vVec,NewsVec,NodeToEvolve,BVec,bVec,LambdaVec)$State)[1,]
#   NewvVec=vVec
#   NewvVec[NodeToEvolve]=min(bVec[NodeToEvolve],rpois(1,LambdaVec[NodeToEvolve]))
#   # NewvVec=NewMeanVState(vVec,NewsVec,NodeToEvolve,BVec,bVec,LambdaVec)
#   return(NewvVec)
# }
SimulationForEvolution<-function(NumberOfRunSteps,HeuristicDepth,HeuristicFunction,n,AdjacencyMatrix,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,SimulationScenario=NULL,vMaxVec=NULL)
{
#Set up simulation matrix and tracking
if(is.null(SimulationScenario))
{
SimulationScenario=CreateSimulationScenario(NumberOfRunSteps,n,LambdaVec)
}
#This vector tracks which column to currently use in each row
TrackingScenario=rep(1,n)
BVec=ceiling(xVec)
if(is.null(vMaxVec))
{
#Create vMaxVec
vMaxVec=CreateVMaxVector(n,LambdaVec,bVec,xVec)
}
RunCost=vector(length=NumberOfRunSteps)
SeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
CumulativeSeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
AllInfo=matrix(list(),nrow=NumberOfRunSteps,ncol=4) #All info stores; state, decision , cost from arrival , cost from observed
for(run in 0:NumberOfRunSteps)
{
print(paste("On run ",toString(run)))
if(run==0)
{
#Set up initial States
StartNode=StartingNodeHeuristic(n,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Starting at ",toString(StartNode)))
sVec=BVec+1
sVec[StartNode]=1
print("Current S is ")
print(sVec)
vVec=vector(length=n)
for(i in 1:n)
{
if(i==StartNode)
{
#vVec[i]=TruncPoissionMean(LambdaVec[i],bVec[i])
vVec[i]=0
print(paste("I have just set the V to",toString(vVec[i]),"Using lam=",toString(LambdaVec[i])," and b=",toString(bVec[i])))
}
else
{
vVec[i]=0
}
}
print("Current v is")
print(vVec)
}
else
{
#Perform a run
OldsVec=sVec
OldvVec=vVec
print("Current S is ")
print(OldsVec)
print("Current V is ")
print(OldvVec)
#decide where to move to using heuristic
MoveToNode=HeuristicFunction(HeuristicDepth,n,AdjacencyMatrix,IndexForNodeFunction,OldsVec,OldvVec,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Choosing to move to",toString(MoveToNode)))
#Calculate cost of doing such an action
RunCost[run]=CostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)
SeperatedRunCost[run,1]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToArrivals
SeperatedRunCost[run,2]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToObserved
if(run==1)
{
CumulativeSeperatedRunCost[run,1]=SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=SeperatedRunCost[run,2]
}
else
{
CumulativeSeperatedRunCost[run,1]=CumulativeSeperatedRunCost[run-1,1]+SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=CumulativeSeperatedRunCost[run-1,2]+SeperatedRunCost[run,2]
}
print(paste("Cost of action is",toString(RunCost[run])))
#Evolve System
sVec=NewSState(OldsVec,MoveToNode,BVec)
#print("Evolved S is ")
#print(sVec)
#Creating new vVec using scenario
vVec=OldvVec
vVec[MoveToNode]=min(SimulationScenario[MoveToNode,TrackingScenario[MoveToNode]],bVec[MoveToNode])
TrackingScenario[MoveToNode]=TrackingScenario[MoveToNode]+1
#vVec=NewMeanVState(OldvVec,sVec,MoveToNode,BVec,bVec,LambdaVec)
#print("Evolved v is")
#print(vVec)
AllInfo[[run,1]]=c(sVec,vVec)
AllInfo[[run,2]]=MoveToNode
AllInfo[[run,3]]=SeperatedRunCost[run,1]
AllInfo[[run,4]]=SeperatedRunCost[run,2]
print(paste("Moved to ",toString(MoveToNode),"Costing ",toString(RunCost[run])))
}
}
AverageCost=sum(RunCost)/NumberOfRunSteps
print(paste("Average cost is ",toString(AverageCost)))
return(list(Average=AverageCost,CostForStep=RunCost,SeperatedCostForStep=SeperatedRunCost,CumulativeSeperatedCostForStep=CumulativeSeperatedRunCost,FullInfoMatrix=AllInfo))
}
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
print("We search for")
print(CurrentState)
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace)
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(B[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace)
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)
print(CurrentState[1])
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)
print(CurrentState[1])
print(BVec[i])
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
print(BVec[i])
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
print(CurrentState[i])
print(BVec[i])
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
n=length(CurrentState)/2
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
print(CurrentState[i])
print(BVec[i])
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
n=length(CurrentState)/2
l=length(CurrentState)
n=l/2
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
l=length(CurrentState)
n=l/2
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
print(CurrentState[i])
print(BVec[i])
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
l=length(CurrentState)
n=l/2
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
l=length(CurrentState)
n=l/2
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
return(AgreeAtStep)
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
#This function is desinged to take in the FullInfoMatrix and compare its decisions to actions from some policy
CompareSimulationInfoToPolicy<-function(FullInfo,ActionPolicy,StateSpace,BVec)
{
AgreeAtStep=vector(length=nrow(FullInfo))
for(i in 1:nrow(FullInfo))
{
#For each step we now compare the decision to the policy
CurrentState=FullInfo[[i,1]]
Decision=FullInfo[[i,2]]
l=length(CurrentState)
n=l/2
#Note here we retain the information for the observed when in state B+1, we will now remove this
for(i in 1:n)
{
if(CurrentState[i]==(BVec[i]+1))
{
CurrentState[i+n]=0
}
}
CurrentStateID=IdenityRow(CurrentState,StateSpace)
PolicyDecision=ActionPolicy[CurrentStateID]
print(paste("Our Decision at state ",toString(CurrentState)))
print(paste("Proposed by simulation is: ",toString(Decision)," and policy suggests: ",toString(PolicyDecision)))
if(Decision==PolicyDecision)
{
AgreeAtStep[i]=1
}
else
{
AgreeAtStep[i]=0
}
}
return(AgreeAtStep)
}
CompareSimulationInfoToPolicy(FullInfoMatrix,Actions,StateSpace,c(2,2,3,3))
