print(paste("We are in heurisitic func:",toString(HeuristicFuncNum),
" depth:",toString(HeuristicDepthNum)," index type:",toString(IndexFuncNum)))
print("We are creating the Heuristic Policy")
}
PolicyByHeuristic=HeuristicPolicy(ListOfHeuristicDepths[HeuristicDepthNum],ListOfHeuristicFunctions[[HeuristicFuncNum]],
n,AdjacencyMatrix,ListOfIndexForNodeFunctions[[IndexFuncNum]],CostVec,LambdaVec,bVec,xVec,StateSpace)
if(PrintOutput)
{
print("Policy Has been created")
}
#Run the heuristic
ValueItByHeuristic=ValueIterationForPolicy(MaxStepsForIteration,ToleranceForIt,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,PolicyByHeuristic)
ValueFuncByHeuristic=ValueItByHeuristic$ValueFunction
ValueFunSteps=ValueItByHeuristic$StepsRun
AverageByFunc=mean(ValueFuncByHeuristic)/ValueFunSteps
#We now work out the level of error and return it
AbsError=ValueItByHeuristic$UpperBound - DualObjectiveValue
PercentageError=(AbsError/DualObjectiveValue) *100
AltAbsError=AverageByFunc-DualObjectiveValue
AltPercentageError=(AltAbsError/DualObjectiveValue) *100
if(PrintOutput)
{
print(paste("Percentage Error by Iteration is:",toString(PercentageError)))
print(paste("Percentage Error by Function is:",toString(AltPercentageError)))
}
Errors[counter,1]=HeuristicFuncNum
Errors[counter,2]=HeuristicDepthNum
Errors[counter,3]=IndexFuncNum
Errors[counter,4]=PercentageError
PolicyList[[counter]]=PolicyByHeuristic
print(PolicyList)
counter=counter+1
}
}
}
#It is worth noting that by the ordering the structure is BigBlocks (with heuristic func), small blocks (with heuristic depth) and elements (with index func)
#Now identify the best Heuristic
MinError=min(Errors[,4])
IDBestHeurisitic=which(Errors[,4]==MinError)
print(IDBestHeurisitic)
BestHeuristics=Errors[IDBestHeurisitic,1:3]
return(list(Errors=Errors,MinError=MinError,BestHeuristics=BestHeuristics))
}
RunTestForMultipleHeuristics(matrix(rep(1,16),nrow=4),c(1.2,1.8,2.2,2.8),rep(2,4),rep(1,4),rep(1/4,4),ListOfHeuristics,ListOfDepths,ListOfIndices,500)
RunTestForMultipleHeuristics(matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),ListOfHeuristics,ListOfDepths,ListOfIndices,500)
RunTestForMultipleHeuristics(matrix(rep(1,16),nrow=4),c(1.2,1.8,2.2,2.8),rep(1,4),rep(1,4),rep(1/4,4),ListOfHeuristics,ListOfDepths,ListOfIndices,500)
RunTestForMultipleHeuristics(matrix(rep(1,16),nrow=4),c(1.2,1.8,2.2,2.8),rep(1,4),rep(1,4),rep(1/10,4),ListOfHeuristics,ListOfDepths,ListOfIndices,500)
FlatIndexForNode<-function(s,v,Cost,Lambda,b,x,vMax)
{
#First calculate B
B=ceiling(x)
if(s <= B && v < (vMax+1))
{
return(Delta(tilde = FALSE,Cost,Lambda,b,x,v,vMax)*(1/B))
}
else if(s <= B && v >=(vMax+1))
{
return(Delta(tilde = FALSE,Cost,Lambda,b,x,v,vMax)*(1/B))
}
else if(s==(B+1) && v < vMax)
{
return(Delta(tilde = FALSE,Cost,Lambda,b,x,v+1,vMax))
}
else if(s==(B+1) && v >= vMax)
{
return(Delta(tilde = TRUE,Cost,Lambda,b,x,v+1,vMax))
}
else
{
print("Error")
}
}
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,4,1,3.5,0,2,0,1,1,1)
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,4,1,3.5,0,2,0,1,1,1)
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,,4,4,1,3.5,0,2,0,1,1,1)
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,,4,4,1,2.5,0,2,0,1,1,1)
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,4,4,1,2.5,0,2,0,1,1,1)
#This functions generates a random adjacency matrix
GenerateAdjConnectedMatrix<-function(NumNodes,NumEdges)
{
stopifnot(NumEdges>=(NumNodes-1))
stopifnot(NumEdges<=(NumNodes+1)*(NumNodes/2))
AdjacencyMatrix=matrix(0,nrow=NumNodes,ncol=NumNodes)
S=sample.int(NumNodes,size=1)
NS=seq(1,NumNodes,1)
NS=NS[NS!=S]
#We now construct it by connecting
while(length(NS)!=0)
{
#Pick a node at random to be include
if(length(NS)==1)
{
NodeToBeAdded=NS
}
else
{
NodeToBeAdded=sample(NS,size=1)
}
#Now pick a random node to connect it to
if(length(S)==1)
{
ConnectionToS=S
}
else
{
ConnectionToS=sample(S,size=1)
}
#Now add this edge into the graph
AdjacencyMatrix[NodeToBeAdded,ConnectionToS]=1
AdjacencyMatrix[ConnectionToS,NodeToBeAdded]=1
#We now removed this node from not selected and add it to selected
S=c(S,NodeToBeAdded)
NS=NS[NS!=NodeToBeAdded]
}
#Now we have a spanning tree, so
NodesNeeded=NumEdges-(NumNodes-1)
Consider=lower.tri(AdjacencyMatrix,diag=FALSE)
Consider=Consider & (AdjacencyMatrix==0)
#Now we add at random these edges into this random spanning tree
ZerosInMatrix=which(Consider==TRUE)
#Create a matrix which we will later transpose and add on
AddOn=matrix(0,nrow=NumNodes,ncol=NumNodes)
if(NodesNeeded>0)
{
if(length(ZerosInMatrix)==1)
{
EdgesToAdd=ZerosInMatrix
}
else
{
EdgesToAdd=sample(ZerosInMatrix,size=NodesNeeded)
}
AddOn[EdgesToAdd]=1
}
#Add on the edges symmetrically
AdjacencyMatrix=AdjacencyMatrix +AddOn + t(AddOn)
#We now add diagonal ones
for(i in 1:NumNodes)
{
AdjacencyMatrix[i,i]=1
}
return(AdjacencyMatrix)
}
testrun=RunTestForMultipleScenarios(1,ListOfHeuristics,ListOfDepths,ListOfIndices,300,4,4,1,2.5,0,2,0,1,1,1)
View(testrun)
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],ListOfHeuristics,ListOfDepths,ListOfIndices,500)
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]])
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],EqualStepIndexForNode,testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]])
PolicyByHeuristicFortestrunB1E
PolicyByHeuristicFortestrunB1E
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]])
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],EqualStepIndexForNode,testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]])
HeuristicPolicy<-function(HeuristicDepth,HeuristicFunction,n,AdjacencyMatrix,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,StateSpace=NULL,vMaxVec=NULL)
{
BVec=ceiling(xVec)
Policy=list()
if(is.null(StateSpace))
{
StateSpace=CreateSVStates(n,BVec,bVec)
}
#For each state we will apply our algorithm to get a policy
for(StateNumber in 1:nrow(StateSpace))
{
#For each state we will find what the Heurisitic tells us to do
State=StateSpace[StateNumber,]
print(State)
MoveToNode=HeuristicFunction(HeuristicDepth,n,AdjacencyMatrix,IndexForNodeFunction,State[1:n],State[(n+1):(2*n)],CostVec,LambdaVec,bVec,xVec,vMaxVec)
#We record in a list the policy
Policy[[StateNumber]]=MoveToNode
}
return(Policy)
}
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],EqualStepIndexForNode,testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]])
PolicyByHeuristicFortestrunB1E=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],EqualStepIndexForNode,testrun[[6]],testrun[[7]],testrun[[5]],testrun[[4]])
PolicyByHeuristicFortestrunB1E
StateSpacetestrun=CreateSVStates(4,celing(testrun[[4]]),c(0,1,0,2))
StateSpacetestrun=CreateSVStates(4,ceiling(testrun[[4]]),c(0,1,0,2))
StateSpacetestrun
ValueIterationForPolicy(100,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=FALSE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
print(NewValueFunction)
print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
ValueIterationForPolicy(100,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=FALSE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
#print(NewValueFunction)
print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
ValueIterationForPolicy(100,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
StateSpacetestrun
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=FALSE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
print(NewValueFunction)
#print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
ValueIterationForPolicy(100,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=FALSE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
#print(NewValueFunction)
print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
ValueIterationForPolicy(100,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
ValueIterationForPolicy(1000,0.001,StateSpacetestrun,testrun[[3]],testrun[[4]],testrun[[5]],testrun[[6]],testrun[[7]],PolicyByHeuristicFortestrunB1E)
StateSpacetestrun
PolicyByHeuristicFortestrunB1E
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5],testrun[[7]],testrun[[6]],ListOfHeuristics,ListOfDepths,ListOfIndices,300)
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5]],testrun[[7]],testrun[[6]],ListOfHeuristics,ListOfDepths,ListOfIndices,300)
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=FALSE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
#print(NewValueFunction)
#print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5]],testrun[[7]],testrun[[6]],ListOfHeuristics,ListOfDepths,ListOfIndices,300)
PolicyByHeuristicFortestrunB1P=HeuristicPolicy(1,MultiStepBenefitHeuristic,4,testrun[[3]],PlainIndexForNode,testrun[[7]],testrun[[6]],testrun[[5]],testrun[[4]])
PolicyByHeuristicFortestrunB1P
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5]],testrun[[7]],testrun[[6]],ListOfHeuristics,ListOfDepths,ListOfIndices,300)
ValueIterationForPolicy<-function(MaxNoSteps,Tolerance,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PrintOutput=TRUE)
{
step=1
BoundWidthError=Tolerance+1
PriorValueFunction=ValueFunctionForPolicy(0,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy)
while(step<=MaxNoSteps && BoundWidthError>=Tolerance)
{
if(PrintOutput)
{
print(paste("On Step ",toString(step)))
}
#Work out the value vector for this number of steps
NewValueFunction=ValueFunctionForPolicy(step,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Policy,PriorValueFunction)
#For this state calcluate min and max for all states
CostBetweenSteps=NewValueFunction-PriorValueFunction
MaxForStates=max(CostBetweenSteps)
MinForStates=min(CostBetweenSteps)
#print(NewValueFunction)
#print(CostBetweenSteps)
BoundWidth=MaxForStates-MinForStates
if(BoundWidth==0)
{
BoundWidthError=0
}
else
{
BoundWidthError=BoundWidth/MinForStates
}
step=step+1
PriorValueFunction=NewValueFunction
if(PrintOutput)
{
print(MinForStates)
print(MaxForStates)
}
}
if(BoundWidthError<Tolerance)
{
if(PrintOutput)
{
print("Returning due to tolerance reached")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
else
{
if(PrintOutput)
{
print("Returning due to time out")
}
return(list(LowerBound=MinForStates,UpperBound=MaxForStates,ValueFunction=NewValueFunction,StepsRun=step-1))
}
}
RunTestForMultipleHeuristics(testrun[[3]],testrun[[4]],testrun[[5]],testrun[[7]],testrun[[6]],ListOfHeuristics,ListOfDepths,ListOfIndices,300)
