CurrentState=StateSpace[state,]
#Current node is
CurrentNode=which.min(CurrentState[1:n])
#For each state we calculate all the values
OptionsVector=vector(length=n)
#for each option of node to move to calculate the cost and add the previous cost
for(option in 1:n)
{
if(AdjacencyMatrix[CurrentNode,option]==1)
{
OptionsVector[option]=CostOfAction(CurrentState,option,n,CostVec,xVec,LambdaVec) #Cost of action
#We now add the expected future cost, this means a proportion for each possible v state we can transistion to by taking this action
#We can retrive the probability and states from a function
EvolvedStates=NewSVState(CurrentState,option,BVec,bVec,LambdaVec)$State
#We now use the scenario to idenity the evolved state and prob=1
EvolvedState=EvolvedStates[Scenario[CurrentNode,ScenarioTracking[CurrentNode]],]
print(EvolvedState)
ScenarioTracking[CurrentNode]=ScenarioTracking[CurrentNode]+1
IDEvolvedState=IdenityRow(EvolvedState,StateSpace)
OptionsVector[option]=OptionsVector[option]+PriorValueFunction[IDEvolvedState]
}
else
{
OptionsVector[option]=NaN
}
}
#Set the Value Vector for that state
ValueVector[state]=min(OptionsVector)
#We will also store the action used to achieve this.
AddOnActionsMatrix[[1,state]]=which(OptionsVector==ValueVector[state])
}
ActionsMatrix=rbind(PriorActionsMatrix,AddOnActionsMatrix)
}
#Return all values
return(list(Values=ValueVector,Actions=ActionsMatrix))
}
ValueFunctionForScenario(1,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
#Function to work out the value for a particular number of steps
#Expects states to be passed as a matrix (with rows being a state with s_1 , s_2,...,s_n,v_1,...,v_2)
ValueFunctionForScenario<-function(Steps,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Scenario,ScenarioTracking=NULL,PriorValueFunction=NULL,PriorActionsMatrix=NULL)
{
n=ncol(StateSpace)/2
if(is.null(ScenarioTracking))
{
ScenarioTracking=rep(1,n)
}
StateSpaceSize=nrow(StateSpace)
n=nrow(AdjacencyMatrix)
BVec=ceiling(xVec)
#Stores the value of this iteration
ValueVector=rep(0,StateSpaceSize)
#Store a list of actions for this iteration
AddOnActionsMatrix=matrix(list(),nrow=1,ncol=StateSpaceSize)
if(Steps==0) #Base case
{
return(list(Values=ValueVector,Actions=AddOnActionsMatrix))
}
else if(Steps!=0)
{
#Work out previous step
if(is.null(PriorValueFunction) || is.null(PriorActionsMatrix))
{
Prior=ValueFunction(Steps-1,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec)
PriorValueFunction=Prior$Values
PriorActionsMatrix=Prior$Actions
}
#Form a vector from which to take the minimum for all states
for(state in 1:StateSpaceSize)
{
#Current state is
CurrentState=StateSpace[state,]
#Current node is
CurrentNode=which.min(CurrentState[1:n])
#For each state we calculate all the values
OptionsVector=vector(length=n)
#for each option of node to move to calculate the cost and add the previous cost
for(option in 1:n)
{
if(AdjacencyMatrix[CurrentNode,option]==1)
{
OptionsVector[option]=CostOfAction(CurrentState,option,n,CostVec,xVec,LambdaVec) #Cost of action
#We now add the expected future cost, this means a proportion for each possible v state we can transistion to by taking this action
#We can retrive the probability and states from a function
EvolvedStates=NewSVState(CurrentState,option,BVec,bVec,LambdaVec)$State
#We now use the scenario to idenity the evolved state and prob=1
EvolvedState=EvolvedStates[Scenario[CurrentNode,ScenarioTracking[CurrentNode]],]
ScenarioTracking[CurrentNode]=ScenarioTracking[CurrentNode]+1
print(EvolvedState)
print(StateSpace)
IDEvolvedState=IdenityRow(EvolvedState,StateSpace)
OptionsVector[option]=OptionsVector[option]+PriorValueFunction[IDEvolvedState]
}
else
{
OptionsVector[option]=NaN
}
}
#Set the Value Vector for that state
ValueVector[state]=min(OptionsVector)
#We will also store the action used to achieve this.
AddOnActionsMatrix[[1,state]]=which(OptionsVector==ValueVector[state])
}
ActionsMatrix=rbind(PriorActionsMatrix,AddOnActionsMatrix)
}
#Return all values
return(list(Values=ValueVector,Actions=ActionsMatrix))
}
ValueFunctionForScenario(1,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
#Function to work out the value for a particular number of steps
#Expects states to be passed as a matrix (with rows being a state with s_1 , s_2,...,s_n,v_1,...,v_2)
ValueFunctionForScenario<-function(Steps,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Scenario,ScenarioTracking=NULL,PriorValueFunction=NULL,PriorActionsMatrix=NULL)
{
n=ncol(StateSpace)/2
if(is.null(ScenarioTracking))
{
ScenarioTracking=rep(1,n)
}
StateSpaceSize=nrow(StateSpace)
n=nrow(AdjacencyMatrix)
BVec=ceiling(xVec)
#Stores the value of this iteration
ValueVector=rep(0,StateSpaceSize)
#Store a list of actions for this iteration
AddOnActionsMatrix=matrix(list(),nrow=1,ncol=StateSpaceSize)
if(Steps==0) #Base case
{
return(list(Values=ValueVector,Actions=AddOnActionsMatrix))
}
else if(Steps!=0)
{
#Work out previous step
if(is.null(PriorValueFunction) || is.null(PriorActionsMatrix))
{
Prior=ValueFunction(Steps-1,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec)
PriorValueFunction=Prior$Values
PriorActionsMatrix=Prior$Actions
}
#Form a vector from which to take the minimum for all states
for(state in 1:StateSpaceSize)
{
#Current state is
CurrentState=StateSpace[state,]
#Current node is
CurrentNode=which.min(CurrentState[1:n])
#For each state we calculate all the values
OptionsVector=vector(length=n)
#for each option of node to move to calculate the cost and add the previous cost
for(option in 1:n)
{
if(AdjacencyMatrix[CurrentNode,option]==1)
{
OptionsVector[option]=CostOfAction(CurrentState,option,n,CostVec,xVec,LambdaVec) #Cost of action
#We now add the expected future cost, this means a proportion for each possible v state we can transistion to by taking this action
#We can retrive the probability and states from a function
EvolvedStates=NewSVState(CurrentState,option,BVec,bVec,LambdaVec)$State
#We now use the scenario to idenity the evolved state and prob=1
EvolvedState=EvolvedStates[Scenario[CurrentNode,ScenarioTracking[CurrentNode]]+1,]
ScenarioTracking[CurrentNode]=ScenarioTracking[CurrentNode]+1
print(EvolvedState)
print(StateSpace)
IDEvolvedState=IdenityRow(EvolvedState,StateSpace)
OptionsVector[option]=OptionsVector[option]+PriorValueFunction[IDEvolvedState]
}
else
{
OptionsVector[option]=NaN
}
}
#Set the Value Vector for that state
ValueVector[state]=min(OptionsVector)
#We will also store the action used to achieve this.
AddOnActionsMatrix[[1,state]]=which(OptionsVector==ValueVector[state])
}
ActionsMatrix=rbind(PriorActionsMatrix,AddOnActionsMatrix)
}
#Return all values
return(list(Values=ValueVector,Actions=ActionsMatrix))
}
ValueFunctionForScenario(1,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
View(Scenario)
Scenario=CreateSimulationScenario(1000,3,rep(1/3,3))
#Function to work out the value for a particular number of steps
#Expects states to be passed as a matrix (with rows being a state with s_1 , s_2,...,s_n,v_1,...,v_2)
ValueFunctionForScenario<-function(Steps,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec,Scenario,ScenarioTracking=NULL,PriorValueFunction=NULL,PriorActionsMatrix=NULL)
{
n=ncol(StateSpace)/2
if(is.null(ScenarioTracking))
{
ScenarioTracking=rep(1,n)
}
StateSpaceSize=nrow(StateSpace)
n=nrow(AdjacencyMatrix)
BVec=ceiling(xVec)
#Stores the value of this iteration
ValueVector=rep(0,StateSpaceSize)
#Store a list of actions for this iteration
AddOnActionsMatrix=matrix(list(),nrow=1,ncol=StateSpaceSize)
if(Steps==0) #Base case
{
return(list(Values=ValueVector,Actions=AddOnActionsMatrix))
}
else if(Steps!=0)
{
#Work out previous step
if(is.null(PriorValueFunction) || is.null(PriorActionsMatrix))
{
Prior=ValueFunction(Steps-1,StateSpace,AdjacencyMatrix,xVec,bVec,CostVec,LambdaVec)
PriorValueFunction=Prior$Values
PriorActionsMatrix=Prior$Actions
}
#Form a vector from which to take the minimum for all states
for(state in 1:StateSpaceSize)
{
#Current state is
CurrentState=StateSpace[state,]
#Current node is
CurrentNode=which.min(CurrentState[1:n])
#For each state we calculate all the values
OptionsVector=vector(length=n)
#for each option of node to move to calculate the cost and add the previous cost
for(option in 1:n)
{
if(AdjacencyMatrix[CurrentNode,option]==1)
{
OptionsVector[option]=CostOfAction(CurrentState,option,n,CostVec,xVec,LambdaVec) #Cost of action
#We now add the expected future cost, this means a proportion for each possible v state we can transistion to by taking this action
#We can retrive the probability and states from a function
EvolvedStates=NewSVState(CurrentState,option,BVec,bVec,LambdaVec)$State
#We now use the scenario to idenity the evolved state and prob=1
EvolvedState=EvolvedStates[(min(bVec[CurrentNode],Scenario[CurrentNode,ScenarioTracking[CurrentNode]])+1),]
ScenarioTracking[CurrentNode]=ScenarioTracking[CurrentNode]+1
IDEvolvedState=IdenityRow(EvolvedState,StateSpace)
OptionsVector[option]=OptionsVector[option]+PriorValueFunction[IDEvolvedState]
}
else
{
OptionsVector[option]=NaN
}
}
#Set the Value Vector for that state
ValueVector[state]=min(OptionsVector)
#We will also store the action used to achieve this.
AddOnActionsMatrix[[1,state]]=which(OptionsVector==ValueVector[state])
}
ActionsMatrix=rbind(PriorActionsMatrix,AddOnActionsMatrix)
}
#Return all values
return(list(Values=ValueVector,Actions=ActionsMatrix))
}
Scenario=CreateSimulationScenario(1000,3,rep(1/3,3))
ValueFunctionForScenario(1,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
ValueFunctionForScenario(10,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
ValueFunctionForScenario(100,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
ValueFunctionForScenario(1000,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)
min(ValueFunctionForScenario(100,StateSpace,matrix(rep(1,9),nrow=3),c(1.2,1.8,2.2),rep(2,3),rep(1,3),rep(1/3,3),Scenario)$Values)
FullInfo=SimulationForEvolution(100,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
CompareSimulationInfoToPolicy(FullInfo,PolicyByDual,StateSpace,c(2,2,3))
FullInfo=SimulationForEvolution(1000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
CompareSimulationInfoToPolicy(FullInfo,PolicyByDual,StateSpace,c(2,2,3))
FullInfo=SimulationForEvolution(1000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
0.005/0.15
Scenario=CreateSimulationScenario(5000,3,rep(1/3,3))
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
sum(Scenario)
CompareSimulationInfoToPolicy(FullInfo,PolicyByDual,StateSpace,c(2,2,3))
RunPolicyForScenario(5000,PolicyByDual,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
RunPolicyForScenario(5000,PolicyByDual,3matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
RunPolicyForScenario(5000,PolicyByDual,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)
library(gtools)
library(utils)
library(lpSolve)
RunPolicyForScenario(5000,PolicyByDual,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)
RunPolicyForScenario(5000,PolicyByDual,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$Average
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$FullInfoMatrix
RunPolicyForScenario(5000,PolicyByDual,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),Scenario)$Average
0.00014/0.15082
sum(Scenario)
list(c(1,2,3),c(2,4),4)
list(c(1,2,3),c(2,4),4)[[2]]
matrix(list(c(1,2),3,c(2,4),c(4,5)),nrow=2)
#This function returns a vector for the simulation to use
CreateSimulationScenario<-function(NoSteps,n,LambdaVec)
{
Scenario=matrix(0,nrow=n,ncol=NoSteps)
for(i in 1:n)
{
for(j in 1:NoSteps)
{
Scenario[i,j]=rpois(1,LambdaVec[i])
}
}
return(Scenario)
}
# SimulateVStateEvolution<-function(NodeToEvolve,NewsVec,vVec,xVec,LambdaVec,bVec)
# {
#   BVec=ceiling(xVec)
#   #NewvVec=(NewVState(vVec,NewsVec,NodeToEvolve,BVec,bVec,LambdaVec)$State)[1,]
#   NewvVec=vVec
#   NewvVec[NodeToEvolve]=min(bVec[NodeToEvolve],rpois(1,LambdaVec[NodeToEvolve]))
#   # NewvVec=NewMeanVState(vVec,NewsVec,NodeToEvolve,BVec,bVec,LambdaVec)
#   return(NewvVec)
# }
SimulationForEvolution<-function(NumberOfRunSteps,HeuristicDepth,HeuristicFunction,n,AdjacencyMatrix,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,BurnOut=0,SimulationScenario=NULL,vMaxVec=NULL)
{
#Set up simulation matrix and tracking
if(is.null(SimulationScenario))
{
SimulationScenario=CreateSimulationScenario(NumberOfRunSteps,n,LambdaVec)
}
#This vector tracks which column to currently use in each row
TrackingScenario=rep(1,n)
BVec=ceiling(xVec)
if(is.null(vMaxVec))
{
#Create vMaxVec
vMaxVec=CreateVMaxVector(n,LambdaVec,bVec,xVec)
}
RunCost=vector(length=NumberOfRunSteps)
SeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
CumulativeSeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
AllInfo=matrix(list(),nrow=NumberOfRunSteps,ncol=4) #All info stores; state, decision , cost from arrival , cost from observed
for(run in 0:NumberOfRunSteps)
{
print(paste("On run ",toString(run)))
if(run==0)
{
#Set up initial States
StartNode=StartingNodeHeuristic(n,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Starting at ",toString(StartNode)))
sVec=BVec+1
sVec[StartNode]=1
print("Current S is ")
print(sVec)
vVec=vector(length=n)
for(i in 1:n)
{
if(i==StartNode)
{
#vVec[i]=TruncPoissionMean(LambdaVec[i],bVec[i])
vVec[i]=0
print(paste("I have just set the V to",toString(vVec[i]),"Using lam=",toString(LambdaVec[i])," and b=",toString(bVec[i])))
}
else
{
vVec[i]=0
}
}
print("Current v is")
print(vVec)
}
else
{
#Perform a run
OldsVec=sVec
OldvVec=vVec
print("Current S is ")
print(OldsVec)
print("Current V is ")
print(OldvVec)
#decide where to move to using heuristic
MoveToNode=HeuristicFunction(HeuristicDepth,n,AdjacencyMatrix,IndexForNodeFunction,OldsVec,OldvVec,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Choosing to move to",toString(MoveToNode)))
#Calculate cost of doing such an action
RunCost[run]=CostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)
SeperatedRunCost[run,1]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToArrivals
SeperatedRunCost[run,2]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToObserved
if(run==1)
{
CumulativeSeperatedRunCost[run,1]=SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=SeperatedRunCost[run,2]
}
else
{
CumulativeSeperatedRunCost[run,1]=CumulativeSeperatedRunCost[run-1,1]+SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=CumulativeSeperatedRunCost[run-1,2]+SeperatedRunCost[run,2]
}
print(paste("Cost of action is",toString(RunCost[run])))
#Evolve System
sVec=NewSState(OldsVec,MoveToNode,BVec)
#print("Evolved S is ")
#print(sVec)
#Creating new vVec using scenario
vVec=OldvVec
vVec[MoveToNode]=min(SimulationScenario[MoveToNode,TrackingScenario[MoveToNode]],bVec[MoveToNode])
TrackingScenario[MoveToNode]=TrackingScenario[MoveToNode]+1
#vVec=NewMeanVState(OldvVec,sVec,MoveToNode,BVec,bVec,LambdaVec)
#print("Evolved v is")
#print(vVec)
AllInfo[[run,1]]=c(OldsVec,OldvVec)
AllInfo[[run,2]]=MoveToNode
AllInfo[[run,3]]=SeperatedRunCost[run,1]
AllInfo[[run,4]]=SeperatedRunCost[run,2]
print(paste("Moved to ",toString(MoveToNode),"Costing ",toString(RunCost[run])))
}
}
#We apply a burn out to remove the first lot of results (to allow it to reach some equilibrium)
Keep=(BurnOut+1):NumberOfRunSteps
RunCost=RunCost[Keep]
SeperatedRunCost=SeperatedRunCost[Keep,]
CumulativeSeperatedRunCost=CumulativeSeperatedRunCost[Keep,]
AllInfo=AllInfo[Keep,]
AverageCost=sum(RunCost)/NumberOfRunSteps
print(paste("Average cost is ",toString(AverageCost)))
return(list(Average=AverageCost,CostForStep=RunCost,SeperatedCostForStep=SeperatedRunCost,CumulativeSeperatedCostForStep=CumulativeSeperatedRunCost,FullInfoMatrix=AllInfo))
}
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),0,Scenario)$FullInfoMatrix
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),0,Scenario)$FullInfoMatrix
SimulationForEvolution<-function(NumberOfRunSteps,HeuristicDepth,HeuristicFunction,n,AdjacencyMatrix,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,BurnOut=0,SimulationScenario=NULL,vMaxVec=NULL)
{
#Set up simulation matrix and tracking
if(is.null(SimulationScenario))
{
SimulationScenario=CreateSimulationScenario(NumberOfRunSteps,n,LambdaVec)
}
#This vector tracks which column to currently use in each row
TrackingScenario=rep(1,n)
BVec=ceiling(xVec)
if(is.null(vMaxVec))
{
#Create vMaxVec
vMaxVec=CreateVMaxVector(n,LambdaVec,bVec,xVec)
}
RunCost=vector(length=NumberOfRunSteps)
SeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
CumulativeSeperatedRunCost=matrix(0,nrow=NumberOfRunSteps,ncol=2)
AllInfo=matrix(list(),nrow=NumberOfRunSteps,ncol=4) #All info stores; state, decision , cost from arrival , cost from observed
for(run in 0:NumberOfRunSteps)
{
print(paste("On run ",toString(run)))
if(run==0)
{
#Set up initial States
StartNode=StartingNodeHeuristic(n,IndexForNodeFunction,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Starting at ",toString(StartNode)))
sVec=BVec+1
sVec[StartNode]=1
print("Current S is ")
print(sVec)
vVec=vector(length=n)
for(i in 1:n)
{
if(i==StartNode)
{
#vVec[i]=TruncPoissionMean(LambdaVec[i],bVec[i])
vVec[i]=0
print(paste("I have just set the V to",toString(vVec[i]),"Using lam=",toString(LambdaVec[i])," and b=",toString(bVec[i])))
}
else
{
vVec[i]=0
}
}
print("Current v is")
print(vVec)
}
else
{
#Perform a run
OldsVec=sVec
OldvVec=vVec
print("Current S is ")
print(OldsVec)
print("Current V is ")
print(OldvVec)
#decide where to move to using heuristic
MoveToNode=HeuristicFunction(HeuristicDepth,n,AdjacencyMatrix,IndexForNodeFunction,OldsVec,OldvVec,CostVec,LambdaVec,bVec,xVec,vMaxVec)
print(paste("Choosing to move to",toString(MoveToNode)))
#Calculate cost of doing such an action
RunCost[run]=CostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)
SeperatedRunCost[run,1]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToArrivals
SeperatedRunCost[run,2]=SeperatedCostOfAction(c(OldsVec,OldvVec),MoveToNode,n,CostVec,xVec,LambdaVec)$CostDueToObserved
if(run==1)
{
CumulativeSeperatedRunCost[run,1]=SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=SeperatedRunCost[run,2]
}
else
{
CumulativeSeperatedRunCost[run,1]=CumulativeSeperatedRunCost[run-1,1]+SeperatedRunCost[run,1]
CumulativeSeperatedRunCost[run,2]=CumulativeSeperatedRunCost[run-1,2]+SeperatedRunCost[run,2]
}
print(paste("Cost of action is",toString(RunCost[run])))
#Evolve System
sVec=NewSState(OldsVec,MoveToNode,BVec)
#print("Evolved S is ")
#print(sVec)
#Creating new vVec using scenario
vVec=OldvVec
vVec[MoveToNode]=min(SimulationScenario[MoveToNode,TrackingScenario[MoveToNode]],bVec[MoveToNode])
TrackingScenario[MoveToNode]=TrackingScenario[MoveToNode]+1
#vVec=NewMeanVState(OldvVec,sVec,MoveToNode,BVec,bVec,LambdaVec)
#print("Evolved v is")
#print(vVec)
AllInfo[[run,1]]=c(OldsVec,OldvVec)
AllInfo[[run,2]]=MoveToNode
AllInfo[[run,3]]=SeperatedRunCost[run,1]
AllInfo[[run,4]]=SeperatedRunCost[run,2]
print(paste("Moved to ",toString(MoveToNode),"Costing ",toString(RunCost[run])))
}
}
#We apply a burn out to remove the first lot of results (to allow it to reach some equilibrium)
Keep=(BurnOut+1):NumberOfRunSteps
RunCost=RunCost[Keep]
SeperatedRunCost=SeperatedRunCost[Keep,]
CumulativeSeperatedRunCost=CumulativeSeperatedRunCost[Keep,]
AllInfo=AllInfo[Keep,]
AverageCost=sum(RunCost)/NumberOfRunSteps
print(paste("Average cost is ",toString(AverageCost)))
return(list(Average=AverageCost,CostForStep=RunCost,SeperatedCostForStep=SeperatedRunCost,CumulativeSeperatedCostForStep=CumulativeSeperatedRunCost,FullInfoMatrix=AllInfo))
}
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),0,Scenario)$FullInfoMatrix
FullInfo=SimulationForEvolution(5000,3,MultiStepPenaltyHeuristic,3,matrix(rep(1,9),nrow=3),PlainIndexForNode,rep(1,3),rep(1/3,3),rep(2,3),c(1.2,1.8,2.2),0,Scenario)$FullInfoMatrix
